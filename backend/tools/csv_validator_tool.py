from crewai.tools import tool
import pandas as pd
import os
from typing import Dict, Any
import sys
sys.path.append(os.path.dirname(os.path.dirname(__file__)))
from models.notas_fiscais import validar_dataframe_cabecalho, validar_dataframe_itens

@tool("csv_validator")
def csv_validator_tool(diretorio_dados: str = "/dados/notasfiscais/") -> str:
    """
    Valida e estrutura arquivos CSV usando modelos Pydantic.
    Transforma os CSVs em DataFrames limpos e confi√°veis, garantindo
    a integridade dos dados antes do processamento pelos outros agentes.
    
    Args:
        diretorio_dados: Diret√≥rio onde est√£o os arquivos CSV extra√≠dos
    
    Returns:
        Relat√≥rio detalhado da valida√ß√£o e estrutura√ß√£o dos dados
    """
    try:
        # Verifica se o diret√≥rio existe
        if not os.path.exists(diretorio_dados):
            return f"‚ùå Erro: Diret√≥rio {diretorio_dados} n√£o encontrado"
        
        # Lista arquivos CSV no diret√≥rio
        csv_files = [f for f in os.listdir(diretorio_dados) if f.lower().endswith('.csv')]
        
        if not csv_files:
            return f"‚ùå Erro: Nenhum arquivo CSV encontrado em {diretorio_dados}"
        
        resultado = f"üîç Iniciando valida√ß√£o Pydantic dos arquivos CSV...\n\n"
        
        # Procura pelos arquivos principais
        arquivo_cabecalho = None
        arquivo_itens = None
        
        for arquivo in csv_files:
            nome_lower = arquivo.lower()
            if 'cabecalho' in nome_lower or 'header' in nome_lower:
                arquivo_cabecalho = arquivo
            elif 'itens' in nome_lower or 'items' in nome_lower:
                arquivo_itens = arquivo
        
        validacoes_realizadas = 0
        total_registros_validos = 0
        erros_encontrados = []
        
        # Valida arquivo de cabe√ßalhos
        if arquivo_cabecalho:
            resultado += f"üìã Validando {arquivo_cabecalho}...\n"
            try:
                # Define tipos espec√≠ficos para evitar convers√µes autom√°ticas problem√°ticas
                dtype_cabecalho = {
                    'N√öMERO': str,
                    'CPF/CNPJ Emitente': str,
                    'CNPJ DESTINAT√ÅRIO': str
                }
                
                df_cabecalho = pd.read_csv(
                    os.path.join(diretorio_dados, arquivo_cabecalho),
                    delimiter=',',
                    decimal='.',
                    dtype=dtype_cabecalho,
                    keep_default_na=False  # Evita convers√£o de strings para NaN
                )
                
                # Usa os nomes originais das colunas do CSV (sem mapeamento)
                # Os novos modelos Pydantic j√° usam os nomes reais das colunas
                df_cabecalho_mapped = df_cabecalho.copy()
                
                # Valida com Pydantic usando os novos modelos
                validacao_cab = validar_dataframe_cabecalho(df_cabecalho_mapped)
                
                resultado += f"   ‚úÖ Registros v√°lidos: {validacao_cab.total_cabecalhos}\n"
                resultado += f"   üìä Total de registros: {len(df_cabecalho)}\n"
                
                if validacao_cab.erros:
                    resultado += f"   ‚ö†Ô∏è Erros encontrados: {len(validacao_cab.erros)}\n"
                    erros_encontrados.extend(validacao_cab.erros[:5])  # Primeiros 5 erros
                
                total_registros_validos += validacao_cab.total_cabecalhos
                validacoes_realizadas += 1
                
                # Salva DataFrame limpo com nomes originais das colunas
                df_limpo_path = os.path.join(diretorio_dados, "cabecalho_validado.csv")
                df_cabecalho_mapped.to_csv(df_limpo_path, index=False)
                resultado += f"   üíæ DataFrame limpo salvo em: cabecalho_validado.csv\n"
                
            except Exception as e:
                erro_msg = f"Erro ao processar {arquivo_cabecalho}: {str(e)}"
                resultado += f"   ‚ùå {erro_msg}\n"
                erros_encontrados.append(erro_msg)
                print(f"DEBUG: Erro detalhado no cabecalho: {e}")
        
        # Valida arquivo de itens
        if arquivo_itens:
            resultado += f"\nüì¶ Validando {arquivo_itens}...\n"
            try:
                # Define tipos espec√≠ficos para evitar convers√µes autom√°ticas problem√°ticas
                dtype_itens = {
                    'N√öMERO': str,
                    'N√öMERO PRODUTO': str,
                    'CPF/CNPJ Emitente': str,
                    'CNPJ DESTINAT√ÅRIO': str
                }
                
                df_itens = pd.read_csv(
                    os.path.join(diretorio_dados, arquivo_itens),
                    delimiter=',',
                    decimal='.',
                    dtype=dtype_itens,
                    keep_default_na=False  # Evita convers√£o de strings para NaN
                )
                
                # Usa os nomes originais das colunas do CSV (sem mapeamento)
                # Os novos modelos Pydantic j√° usam os nomes reais das colunas
                df_itens_mapped = df_itens.copy()
                
                # Valida com Pydantic usando os novos modelos
                validacao_itens = validar_dataframe_itens(df_itens_mapped)
                
                resultado += f"   ‚úÖ Registros v√°lidos: {validacao_itens.total_itens}\n"
                resultado += f"   üìä Total de registros: {len(df_itens)}\n"
                
                if validacao_itens.erros:
                    resultado += f"   ‚ö†Ô∏è Erros encontrados: {len(validacao_itens.erros)}\n"
                    erros_encontrados.extend(validacao_itens.erros[:5])  # Primeiros 5 erros
                
                total_registros_validos += validacao_itens.total_itens
                validacoes_realizadas += 1
                
                # Salva DataFrame limpo com nomes originais das colunas
                df_limpo_path = os.path.join(diretorio_dados, "itens_validado.csv")
                df_itens_mapped.to_csv(df_limpo_path, index=False)
                resultado += f"   üíæ DataFrame limpo salvo em: itens_validado.csv\n"
                
            except Exception as e:
                erro_msg = f"Erro ao processar {arquivo_itens}: {str(e)}"
                resultado += f"   ‚ùå {erro_msg}\n"
                erros_encontrados.append(erro_msg)
                print(f"DEBUG: Erro detalhado nos itens: {e}")
        
        # Processa outros CSVs se necess√°rio
        outros_csvs = [f for f in csv_files if f != arquivo_cabecalho and f != arquivo_itens]
        if outros_csvs:
            resultado += f"\nüìÑ Outros CSVs encontrados: {', '.join(outros_csvs)}\n"
            resultado += f"   ‚ÑπÔ∏è Processamento b√°sico aplicado (sem valida√ß√£o Pydantic espec√≠fica)\n"
        
        # Resumo final
        resultado += f"\nüéØ RESUMO DA VALIDA√á√ÉO:\n"
        resultado += f"   üìÅ Arquivos processados: {validacoes_realizadas}\n"
        resultado += f"   ‚úÖ Total de registros v√°lidos: {total_registros_validos}\n"
        resultado += f"   ‚ùå Total de erros: {len(erros_encontrados)}\n"
        
        if erros_encontrados:
            resultado += f"\n‚ö†Ô∏è PRIMEIROS ERROS ENCONTRADOS:\n"
            for erro in erros_encontrados[:3]:
                resultado += f"   ‚Ä¢ {erro}\n"
        
        if not arquivo_cabecalho or not arquivo_itens:
            resultado += f"\n‚ö†Ô∏è ATEN√á√ÉO: Arquivos padr√£o n√£o encontrados!\n"
            resultado += f"   üîç Esperados: '*cabecalho*.csv' e '*itens*.csv'\n"
            resultado += f"   üìã Dispon√≠veis: {', '.join(csv_files)}\n"
        
        resultado += f"\nüõ°Ô∏è Valida√ß√£o Pydantic conclu√≠da! DataFrames estruturados e prontos para an√°lise."
        
        return resultado
        
    except Exception as e:
        return f"‚ùå Erro inesperado durante a valida√ß√£o: {str(e)}"